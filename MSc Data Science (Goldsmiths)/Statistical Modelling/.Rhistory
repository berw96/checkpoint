# test_set = scale(test_set)
# Fitting simple Linear Regression to the Training Set
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
# Predicting the Test set results
y_predictions = predict(regressor, newdata = test_set)
# Visualizing the Training set results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
color = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
color = 'black') +
ggtitle('Salary vs Experience (Training Set)') +
xlab('Years of Experience') +
ylab('Salary')
# Visualizing the Test set results
library(ggplot2)
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
color = 'blue') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
color = 'black') +
ggtitle('Salary vs Experience (Test Set)') +
xlab('Years of Experience') +
ylab('Estimated Salary')
50_startups.csv
cls
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('Data.csv')
# Importing the dataset
dataset = read.csv('50_Startups.csv')
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('50_Startups.csv')
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
View(dataset)
View(dataset)
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
# Encoding categorical data into a numeric form
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1,2,3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
# Encoding categorical data into a numeric form
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1,2,3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
View(dataset)
View(test_set)
View(training_set)
regressor = lm(formula =  Profit ~ R.D.Spend + Administration + Marketing.Spend + State
data = training_set)
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
# Encoding categorical data into a numeric form
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1,2,3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Multiple Linear Regression model to the training set
# TIP: rather than type out all the input variables ahead of our
# dependent variable, you can type a dot (.): Profit ~ .
regressor = lm(formula =  Profit ~ R.D.Spend + Administration + Marketing.Spend + State
data = training_set)
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
# Encoding categorical data into a numeric form
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1,2,3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Multiple Linear Regression model to the training set
# TIP: rather than type out all the input variables ahead of our
# dependent variable, you can type a dot (.): Profit ~ .
regressor = lm(formula =  Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = training_set)
View(regressor)
summary(regressor)
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
# Encoding categorical data into a numeric form
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1,2,3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Multiple Linear Regression model to the training set
# TIP: rather than type out all the input variables ahead of our
# dependent variable, you can type a dot (.): Profit ~ .
regressor = lm(formula =  Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = training_set)
# Using our model to predict test results
y_predictions = predict(regressor,
newdata = test_set)
y_predictions
View(test_set)
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 5 - Multiple Linear Regression/R/50_Startups.csv')
# Encoding categorical data into a numeric form
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1,2,3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Multiple Linear Regression model to the training set
# TIP: rather than type out all the input variables ahead of our
# dependent variable, you can type a dot (.): Profit ~ .
# R.D.Spend is the only significant input, thus all others
# can be omitted from our formula.
regressor = lm(formula =  Profit ~ .,
data = training_set)
# Using our model to predict test results
y_predictions = predict(regressor,
newdata = test_set)
# Optimizing the model using Backward Elimination
regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = dataset)
summary(regressor)
summary(regressor)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend,
data = dataset)
summary(regressor)
summary(regressor$coefficients)
summary(regressor$qr)
summary(regressor$terms)
summary(regressor$terms$class2)
summary(regressor$terms$class2)
summary(regressor$terms$class2)
summary(regressor$fitted.values)
summary(regressor$formula)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = dataset)
summary(regressor)
summary(regressor$coefficients)
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 3 - Classification/Section 14 - Logistic Regression/R/Social_Network_Ads.csv')
dataset = dataset[3:5]
View(dataset)
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 3 - Classification/Section 14 - Logistic Regression/R/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
dataset
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(test_set)
View(training_set)
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
View(training_set)
View(test_set)
View(training_set)
View(training_set)
classifier = glm(formula = Purchased ~ .,
family = binomial,
data = training_set)
prob_pred = predict(classifier,
type = 'response',
newdata = test_set[-3])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
cm = table(test_set[, 3], y_pred)
cm
install.packages("C:/Users/berw9/Downloads/ElemStatLearn_2015.6.26.tar.gz", repos = NULL, type = "source")
install.packages('ElemStatLearn')
library(ElemStatLearn)
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,
type = 'response',
newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training Set)',
xlab = 'Age',
ylab = 'Estimated Salary',
xlim = range(X1),
ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1), 'green4', 'red3')
# Classification template
# Importing the dataset
dataset = read.csv('C:/Users/berw9/Desktop/Udemy/Machine Learning A-Z (Codes and Datasets)/Part 3 - Classification/Section 14 - Logistic Regression/R/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# Fitting classifier to the Training set
# Create your classifier here
classifier = glm(formula = Purchased ~ .,
family = binomial,
data = training_set)
# Predict test set results using classifier
# excluding binary column
prob_pred = predict(classifier,
type = 'response',
newdata = test_set[-3])
# converting decimal probability predictions to 0s and 1s
y_pred = ifelse(prob_pred > 0.5, 1, 0)
# confusion matrix
cm = table(test_set[, 3], y_pred)
# visualize training set results
install.packages('ElemStatLearn')
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,
type = 'response',
newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training Set)',
xlab = 'Age',
ylab = 'Estimated Salary',
xlim = range(X1),
ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
library(caTools)
#install.packages('caret')
library(caret)
library(class)
# Round fitted values for a given regressional model.
round_fitted_values <- function(x){
for(i in 1:length(x)){
if(x[i] < 0.5){
x[i] = 0
} else if (x[i] >= 0.5){
x[i] = 1
}
}
return(x)
}
# Apply min-max normalization to continuous data.
min_max_norm <- function(x){
x = (x - min(x))/(max(x) - min(x))
return(x)
}
data = read.csv("datasets/Weekly.csv")
setwd("C:/Users/berw9/Desktop/git repos/checkpoint/MSc Data Science (Goldsmiths)/Statistical Modelling")
data = read.csv("datasets/Weekly.csv")
summary(data)
plot(data)
data$Direction = factor(
data$Direction,
levels = c("Down", "Up"),
labels = c(0,1)
)
for(i in 2:8){
data[,i] = min_max_norm(data[,i])
}
set.seed(123)
split = sample.split(data$Direction, SplitRatio = 0.75)
train = subset(data, split == TRUE)
test = subset(data, split == FALSE)
lr_model = glm(
formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = train,
family = binomial)
summary(lr_model)
print(lr_model$fitted.values)
train_actual_values = train$Direction
# Apply rounding to our fitted values.
lr_model$fitted.values = round_fitted_values(lr_model$fitted.values)
predicted_values = lr_model$fitted.values
confusionMatrix(data = train_actual_values, reference = as.factor(predicted_values))
data4 = data
set.seed(123)
split = sample.split(data4$Direction, SplitRatio = 0.75)
train4 = subset(data4, split == TRUE)
test4 = subset(data4, split == FALSE)
lr_model4 = glm(
formula = Direction ~ log(Lag2),
data = train4,
family = binomial
)
data4 = data
set.seed(123)
split = sample.split(data4$Direction, SplitRatio = 0.75)
train4 = subset(data4, split == TRUE)
test4 = subset(data4, split == FALSE)
lr_model4 = glm(
formula = Direction ~ log(Lag2),
data = train4,
family = binomial
)
lr_model4 = glm(
formula = Direction ~ Lag2,
data = train4,
family = binomial
)
lr_model4 = glm(
formula = Direction ~ Lag2**2,
data = train4,
family = binomial
)
lr_model4 = glm(
formula = Direction ~ log(Lag2),
data = train4,
family = binomial
)
lr_model4 = glm(
formula = Direction ~ sqrt(Lag2),
data = train4,
family = binomial
)
train_actual_values4 = data4
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = predicted_values4)
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
train_actual_values4 = data4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
train_actual_values4 = data4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
train_actual_values4 = train4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
data4 = data
set.seed(123)
split = sample.split(data4$Direction, SplitRatio = 0.75)
train4 = subset(data4, split == TRUE)
test4 = subset(data4, split == FALSE)
lr_model4 = glm(
formula = Direction ~ sqrt(Lag2),
data = train4,
family = binomial
)
train_actual_values4 = train4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
probabilities4 = predict(
lr_model4,
type = response,
newdata = test4
)
data4 = data
set.seed(123)
split = sample.split(data4$Direction, SplitRatio = 0.75)
train4 = subset(data4, split == TRUE)
test4 = subset(data4, split == FALSE)
lr_model4 = glm(
formula = Direction ~ sqrt(Lag2),
data = train4,
family = binomial
)
train_actual_values4 = train4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
probabilities4 = predict(
lr_model4,
type = response,
newdata = test4
)
data4 = data
set.seed(123)
split = sample.split(data4$Direction, SplitRatio = 0.75)
train4 = subset(data4, split == TRUE)
test4 = subset(data4, split == FALSE)
lr_model4 = glm(
formula = Direction ~ sqrt(Lag2),
data = train4,
family = binomial
)
train_actual_values4 = train4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
probabilities4 = predict(
lr_model4,
type = 'response',
newdata = test4
)
predictions4 = ifelse(probabilities4 >= 0.5, 1, 0)
test_actual_values4 = test4$Direction
confusionMatrix(data = test_actual_values4, reference = )
data4 = data
set.seed(123)
split = sample.split(data4$Direction, SplitRatio = 0.75)
train4 = subset(data4, split == TRUE)
test4 = subset(data4, split == FALSE)
lr_model4 = glm(
formula = Direction ~ sqrt(Lag2),
data = train4,
family = binomial
)
train_actual_values4 = train4$Direction
lr_model4$fitted.values = round_fitted_values(lr_model4$fitted.values)
predicted_values4 = lr_model4$fitted.values
confusionMatrix(data = train_actual_values4, reference = as.factor(predicted_values4))
probabilities4 = predict(
lr_model4,
type = 'response',
newdata = test4
)
predictions4 = ifelse(probabilities4 >= 0.5, 1, 0)
test_actual_values4 = test4$Direction
confusionMatrix(data = test_actual_values4, reference = as.factor(predictions4))
data5 = data
set.seed(123)
split = sample.split(data5$Direction, SplitRatio = 0.75)
train5 = subset(data5, split == TRUE)
test5 = subset(data5, split == FALSE)
lr_model5 = glm(
formula = Direction ~ Lag2**2,
data = train5,
family = binomial
)
train_actual_values5 = train5$Direction
lr_model5$fitted.values = round_fitted_values(lr_model5$fitted.values)
predicted_values5 = lr_model5$fitted.values
confusionMatrix(data = train_actual_values5, reference = as.factor(predicted_values5))
probabilities5 = predict(
lr_model5,
type = 'response',
newdata = test5
)
predictions5 = ifelse(probabilities5 >= 0.5, 1, 0)
test_actual_values5 = test5$Direction
confusionMatrix(data = test_actual_values5, reference = as.factor(predictions5))
